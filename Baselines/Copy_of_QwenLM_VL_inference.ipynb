{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUsiFUDaq6Q4"
      },
      "outputs": [],
      "source": [
        "!pip install optimum\n",
        "!git clone https://github.com/JustinLin610/AutoGPTQ.git & cd AutoGPTQ\n",
        "!pip install -v ."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0buFl4MP_FfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/QwenLM/Qwen-VL.git"
      ],
      "metadata": {
        "id": "42U6y4Xuz9WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd Qwen-VL\n",
        "# pwd\n",
        "!pip install -r /content/Qwen-VL/requirements.txt"
      ],
      "metadata": {
        "id": "zE6JfRbw0G6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DfcNwwBK01yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "from PIL import Image\n",
        "import os\n",
        "excel_path = '/content/drive/MyDrive/meme_gemini_gptv4.xlsx'\n",
        "image_folder = '/content/drive/MyDrive/meme_abdullah'\n",
        "\n",
        "# Load the Excel file\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# Ensure the 'llava' column exists\n",
        "if 'qwenlm' not in df.columns:\n",
        "    df['qwenlm'] = None\n",
        "\n",
        "# Iterate over each row in the dataframe\n",
        "for index, row in df.iterrows():\n",
        "    meme_id = row['meme_id']\n",
        "    image_path = os.path.join(image_folder, f\"{meme_id}.jpg\")\n",
        "\n",
        "    # Check if the image file exists\n",
        "    if os.path.exists(image_path):\n",
        "        # Read the image\n",
        "        with open(image_path, 'rb') as image_file:\n",
        "            image_data = image_file.read()\n",
        "\n",
        "        # Process the image with your model\n",
        "        image_tag = f'<img>{image_path}</img>'\n",
        "        response, history = model.chat(tokenizer, query=f'{image_tag} 这是什么', history=None)\n",
        "\n",
        "        # Save the generated text to the 'llava' column\n",
        "        print(response)\n",
        "        df.at[index, 'llava'] = response\n",
        "\n",
        "        # Save the updated dataframe to the Excel file after every iteration\n",
        "        with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
        "            df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
        "\n",
        "print(\"Process completed.\")"
      ],
      "metadata": {
        "id": "zV2IV2x58YhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################"
      ],
      "metadata": {
        "id": "FhG7VHe6_GpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade optimum\n",
        "!pip install --upgrade auto-gptq\n",
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "_Dg4w9SLDu5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Note: The default behavior now has injection attack prevention off.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-VL-Chat-Int4\", trust_remote_code=True)\n",
        "\n",
        "# use cuda device\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-VL-Chat-Int4\", device_map=\"cuda\", trust_remote_code=True).eval()\n",
        "\n",
        "# 1st dialogue turn\n",
        "# query = tokenizer.from_list_format([\n",
        "#     {'image': 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg'},\n",
        "#     {'text': '这是什么'},\n",
        "# ])\n",
        "# response, history = model.chat(tokenizer, query=query, history=None)\n",
        "# print(response)\n",
        "# # 图中是一名年轻女子在沙滩上和她的狗玩耍，狗的品种可能是拉布拉多。她们坐在沙滩上，狗的前腿抬起来，似乎在和人类击掌。两人之间充满了信任和爱。\n",
        "\n",
        "# # 2nd dialogue turn\n",
        "# response, history = model.chat(tokenizer, '输出\"击掌\"的检测框', history=history)\n",
        "# print(response)\n",
        "# # <ref>击掌</ref><box>(517,508),(589,611)</box>\n",
        "# image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
        "# if image:\n",
        "#   image.save('1.jpg')\n",
        "# else:\n",
        "#   print(\"no box\")\n"
      ],
      "metadata": {
        "id": "LUAT19sC_I09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = tokenizer.from_list_format([\n",
        "    {'image': 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg'},\n",
        "    {'text': 'explain the meme in english'},\n",
        "])\n",
        "response, history = model.chat(tokenizer, query=query, history=None)\n",
        "print(response)\n",
        "# 图中是一名年轻女子在沙滩上和她的狗玩耍，狗的品种可能是拉布拉多。她们坐在沙滩上，狗的前腿抬起来，似乎在和人类击掌。两人之间充满了信任和爱。\n",
        "\n",
        "# 2nd dialogue turn\n",
        "# response, history = model.chat(tokenizer, 'explain the meme in english', history=history)\n",
        "# print(response)\n",
        "# # <ref>击掌</ref><box>(517,508),(589,611)</box>\n",
        "# image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
        "# if image:\n",
        "#   image.save('1.jpg')\n",
        "# else:\n",
        "#   print(\"no box\")"
      ],
      "metadata": {
        "id": "aRj6_hezE-77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "from PIL import Image\n",
        "import os\n",
        "excel_path = '/content/drive/MyDrive/meme_gemini_gptv4.xlsx'\n",
        "image_folder = '/content/drive/MyDrive/meme_abdullah'\n",
        "count = 0\n",
        "# Load the Excel file\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# Ensure the 'llava' column exists\n",
        "if 'qwenlm' not in df.columns:\n",
        "    df['qwenlm'] = None\n",
        "\n",
        "# Iterate over each row in the dataframe\n",
        "for index, row in df.iterrows():\n",
        "    if pd.notna(row['qwenlm']):\n",
        "      print(\"skip\")\n",
        "      continue\n",
        "\n",
        "    meme_id = row['meme_id']\n",
        "    image_path = os.path.join(image_folder, f\"{meme_id}.jpg\")\n",
        "\n",
        "    # Check if the image file exists\n",
        "    if os.path.exists(image_path):\n",
        "        # Read the image\n",
        "        with open(image_path, 'rb') as image_file:\n",
        "            image_data = image_file.read()\n",
        "\n",
        "        # Process the image with your model\n",
        "        image_tag = f'<img>{image_path}</img>'\n",
        "        response, history = model.chat(tokenizer, query=f'{image_tag} The bot is provided with an image that is a meme. Bot has to provide a summary of the meme, capturing its humour and what makes it humorous. The summary should be clear and engaging', history=None)\n",
        "\n",
        "        # Save the generated text to the 'llava' column\n",
        "        print(response)\n",
        "        print(count)\n",
        "        count =count + 1\n",
        "        df.at[index, 'qwenlm'] = response\n",
        "\n",
        "        # Save the updated dataframe to the Excel file after every iteration\n",
        "        with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
        "            df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
        "\n",
        "print(\"Process completed.\")"
      ],
      "metadata": {
        "id": "-yAJJJ3eEw5n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}